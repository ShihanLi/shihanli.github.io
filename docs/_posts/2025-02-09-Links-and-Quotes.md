---
layout: post
title:  "Links and Quotes Week of Feb 2nd"
date:   2025-02-09 23:24:43 -0800
categories: links
---

### Quoting Sam Altman

> **1. The intelligence of an AI model roughly equals the log of the resources used to train and run it.**  
> These resources are chiefly training compute, data, and inference compute. It appears that you can spend arbitrary amounts of money and get continuous and predictable gains; the scaling laws that predict this are accurate over many orders of magnitude.
>
> **2. The cost to use a given level of AI falls about 10x every 12 months, and lower prices lead to much more use.**  
> You can see this in the token cost from GPT-4 in early 2023 to GPT-4o in mid-2024, where the price per token dropped about 150x in that time period. Moore’s law changed the world at 2x every 18 months; this is unbelievably stronger.
>
> **3. The socioeconomic value of linearly increasing intelligence is super-exponential in nature.**  
> A consequence of this is that we see no reason for exponentially increasing investment to stop in the near future.

— [Sam Altman](https://blog.samaltman.com/three-observations), *Three Observations*


### Quoting Noahpinion

Russia’s invasion of Ukraine in 2022 was a clear-cut case of aggression, yet over time, parts of the American right justified it, leading to uncertainties about U.S. support under Trump. While Trump initially promised a quick peace deal favoring Russian territorial gains and Ukraine's neutrality, he is now frustrated that Putin refuses to settle, prompting him to consider renewed sanctions and continued military aid to Ukraine. If a deal is eventually reached, Ukraine may face territorial losses but could secure long-term independence, much like Finland after World War II, and leave the Russian influence forever.

> Because the MAGA people spent so much time advancing the (false) notion that America itself is at war in Ukraine, that means that if Russia overruns Ukraine now, Trump will feel like he lost a war. And Trump does not like to lose wars — witness how he made a deal with the Taliban to withdraw American troops from Afghanistan, but set the date so that it would be after his term ended.
>
> The problem is that the whole MAGA narrative about Russia’s motives is false, and was always false. Putin has always wanted to conquer all or most of Ukraine — that’s why his first attack in early 2022 was against the Ukrainian capital, and why he sent a military parade column toward Kyiv. It was never really about NATO, or about protecting Russian speakers, or any of that stuff. And as long as his army continues to advance and take more territory in Ukraine, his population is quiescent, and his military manufacturing is humming along, Putin naturally sees little reason to relent. He sees that he’s winning, and he wants to win it all.
>
> President Donald Trump says he wants access to Ukraine’s bonanza of rare earth and critical minerals in exchange for the billions of dollars in military aid Washington has been supplying to Kyiv…It’s an idea previously suggested by Republican senators and Ukrainian President Volodymyr Zelenskyy.
>
> This actually wouldn’t be an empty or symbolic deal, either — Ukraine actually does have a substantial amount of mineral resources. Stepping up Ukraine would be a bit awkward for Trump, who campaigned on reducing that aid. But stranger things have happened in the world of foreign policy.
> 

[Noahpinion](https://www.noahpinion.blog/p/whats-going-to-happen-to-ukraine), *What's going to happen in Ukraine now?*

### Quoting Ben Thompson

The growing value of proprietary data and the implication of AI driven research tools like Deep Research on the prediction markets.

> Hedge funds have long known the value of proprietary data, paying for everything from satellite images to traffic observers and everything in between in order to get a market edge. My suspicion is that work like this is going to become even more valuable as security by obscurity disappears; it's going to be more difficult to harvest alpha from reading endless financial filings when an AI can do that research in a fraction of the time. ((I don't think Deep Research is good at something like this, at least not yet. For example, I generated a report about what happened in 2015 surrounding Amazon's disclosure, and the results were pretty poor; this is, however, the worst the tool will ever be.))
>
> The problem with those hedge fund reports, however, is that they themselves are proprietary; however, they are not a complete secret. After all, the way to monetize that research is through making trades on the open market, which is to say those reports have an impact on prices. Prices are a signal that is available to everyone, and it's going to become an increasingly important one.
> 
> That, by extension, is why AI's like Deep Research are one of the most powerful arguments yet for prediction markets. Prediction markets had their moment in the sun last fall during the U.S. presidential election, when they were far more optimistic about a Trump victory than polls. However, the potential — in fact, the necessity — of prediction markets is only going to increase with AI. AI's capability of knowing everything that is public is going to increase the incentive to keep things secret; prediction markets in everything will provide a profit incentive for knowledge to be disseminated, by price if nothing else.
>
> It is also interesting that prediction markets have become associated with crypto, another technology that is poised to come into its own in an AI-dominated world; infinite content generation increases the value of digital scarcity and verification, just as infinite transparency increases the value of secrecy. AI is likely to be the key to tying all of this together: a combination of verifiable information and understandable price movements may the only way to derive any meaning from the slop that is slowly drowning the Internet.
>
> This is the other reality of AI, and why it is inescapable. Just as the Internet's transparency and freedom to publish has devolved into torrents of information of questionable veracity, requiring ever more heroic efforts to parse, and undeniable opportunities to thrive by building independent brands — like this site — AI will both be the cause of further pollution of the information ecosystem and, simultaneously, the only way out.

[Stratechery](https://stratechery.com/2025/deep-research-and-knowledge-value/), *Deep Research and Knowledge Value*